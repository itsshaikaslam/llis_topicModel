{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reshama trying it out\n",
    "#### 9/25/18"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At Fast.ai we have introduced a new module called fastai.text which replaces the torchtext library that was used in our 2018 dl1 course. The fastai.text module also supersedes the fastai.nlp library but retains many of the key functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/src/anaconda3/envs/fastai/lib/python3.6/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "from fastai.text import *\n",
    "import html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Fastai.text module introduces several custom tokens.\n",
    "\n",
    "We need to download the IMDB large movie reviews from this site: http://ai.stanford.edu/~amaas/data/sentiment/\n",
    "Direct link : [Link](http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz) and untar it into the PATH location. We use pathlib which makes directory traveral a breeze."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in Lessons Learned csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/my_repos/llis_topicModel/python\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATHproject=\"/home/ubuntu/my_repos/llis_topicModel/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(PATHproject+\"data/llis.csv\", encoding = \"ISO-8859-1\", engine='python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LessonId</th>\n",
       "      <th>Submitter1</th>\n",
       "      <th>Title</th>\n",
       "      <th>Abstract</th>\n",
       "      <th>Lesson</th>\n",
       "      <th>Organization</th>\n",
       "      <th>LessonDate</th>\n",
       "      <th>MissionDirectorate</th>\n",
       "      <th>SafetyIssue</th>\n",
       "      <th>Categories</th>\n",
       "      <th>DocNum</th>\n",
       "      <th>Topic</th>\n",
       "      <th>Category</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9501</td>\n",
       "      <td>Bell, Michael</td>\n",
       "      <td>Manhole Arc-Flash Risk Reduction</td>\n",
       "      <td>Power system distribution at Kennedy Space C...</td>\n",
       "      <td>Laboratory testing revealed higher than anti...</td>\n",
       "      <td>KSC</td>\n",
       "      <td>6/6/14</td>\n",
       "      <td>Aeronautics Research, Human Exploration and Op...</td>\n",
       "      <td>True</td>\n",
       "      <td>Energy, Facilities, Industrial Operations, Per...</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>Energy</td>\n",
       "      <td>https://nen.nasa.gov/web/11/viewall/-/viewall/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8018</td>\n",
       "      <td>Bell, Michael</td>\n",
       "      <td>CRCA Sampling Process Lessons Learned</td>\n",
       "      <td>The sampling and analysis processes, used to...</td>\n",
       "      <td>The particle contamination monitoring was in...</td>\n",
       "      <td>KSC</td>\n",
       "      <td>3/11/14</td>\n",
       "      <td>Human Exploration and Operations,</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://nen.nasa.gov/web/11/viewall/-/viewall/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8701</td>\n",
       "      <td>Oberhettinger, David</td>\n",
       "      <td>Take Special Care to Avoid Misprobing When Usi...</td>\n",
       "      <td>An operator error involving mis-probing duri...</td>\n",
       "      <td>The common use of BOBs during subsystem/syst...</td>\n",
       "      <td>JPL</td>\n",
       "      <td>2/18/14</td>\n",
       "      <td>Aeronautics Research, Human Exploration and Op...</td>\n",
       "      <td>True</td>\n",
       "      <td>Integration and Testing, Safety and Mission As...</td>\n",
       "      <td>3</td>\n",
       "      <td>31</td>\n",
       "      <td>Integration and Testing</td>\n",
       "      <td>https://nen.nasa.gov/web/11/viewall/-/viewall/...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   LessonId             Submitter1  \\\n",
       "0      9501          Bell, Michael   \n",
       "1      8018         Bell, Michael    \n",
       "2      8701  Oberhettinger, David    \n",
       "\n",
       "                                               Title  \\\n",
       "0                   Manhole Arc-Flash Risk Reduction   \n",
       "1              CRCA Sampling Process Lessons Learned   \n",
       "2  Take Special Care to Avoid Misprobing When Usi...   \n",
       "\n",
       "                                            Abstract  \\\n",
       "0    Power system distribution at Kennedy Space C...   \n",
       "1    The sampling and analysis processes, used to...   \n",
       "2    An operator error involving mis-probing duri...   \n",
       "\n",
       "                                              Lesson Organization LessonDate  \\\n",
       "0    Laboratory testing revealed higher than anti...          KSC     6/6/14   \n",
       "1    The particle contamination monitoring was in...          KSC    3/11/14   \n",
       "2    The common use of BOBs during subsystem/syst...          JPL    2/18/14   \n",
       "\n",
       "                                  MissionDirectorate  SafetyIssue  \\\n",
       "0  Aeronautics Research, Human Exploration and Op...         True   \n",
       "1                 Human Exploration and Operations,         False   \n",
       "2  Aeronautics Research, Human Exploration and Op...         True   \n",
       "\n",
       "                                          Categories  DocNum  Topic  \\\n",
       "0  Energy, Facilities, Industrial Operations, Per...       1     22   \n",
       "1                                                NaN       2     18   \n",
       "2  Integration and Testing, Safety and Mission As...       3     31   \n",
       "\n",
       "                  Category                                                url  \n",
       "0                   Energy  https://nen.nasa.gov/web/11/viewall/-/viewall/...  \n",
       "1                      NaN  https://nen.nasa.gov/web/11/viewall/-/viewall/...  \n",
       "2  Integration and Testing  https://nen.nasa.gov/web/11/viewall/-/viewall/...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LessonId</th>\n",
       "      <th>Submitter1</th>\n",
       "      <th>Title</th>\n",
       "      <th>Abstract</th>\n",
       "      <th>Lesson</th>\n",
       "      <th>Organization</th>\n",
       "      <th>LessonDate</th>\n",
       "      <th>MissionDirectorate</th>\n",
       "      <th>Categories</th>\n",
       "      <th>DocNum</th>\n",
       "      <th>Topic</th>\n",
       "      <th>Category</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SafetyIssue</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>1401</td>\n",
       "      <td>1401</td>\n",
       "      <td>1387</td>\n",
       "      <td>641</td>\n",
       "      <td>1401</td>\n",
       "      <td>1401</td>\n",
       "      <td>1401</td>\n",
       "      <td>1129</td>\n",
       "      <td>314</td>\n",
       "      <td>1401</td>\n",
       "      <td>1401</td>\n",
       "      <td>314</td>\n",
       "      <td>1401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>236</td>\n",
       "      <td>236</td>\n",
       "      <td>235</td>\n",
       "      <td>227</td>\n",
       "      <td>236</td>\n",
       "      <td>236</td>\n",
       "      <td>236</td>\n",
       "      <td>121</td>\n",
       "      <td>82</td>\n",
       "      <td>236</td>\n",
       "      <td>236</td>\n",
       "      <td>82</td>\n",
       "      <td>236</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             LessonId  Submitter1  Title  Abstract  Lesson  Organization  \\\n",
       "SafetyIssue                                                                \n",
       "False            1401        1401   1387       641    1401          1401   \n",
       "True              236         236    235       227     236           236   \n",
       "\n",
       "             LessonDate  MissionDirectorate  Categories  DocNum  Topic  \\\n",
       "SafetyIssue                                                              \n",
       "False              1401                1129         314    1401   1401   \n",
       "True                236                 121          82     236    236   \n",
       "\n",
       "             Category   url  \n",
       "SafetyIssue                  \n",
       "False             314  1401  \n",
       "True               82   236  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(['SafetyIssue']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>LessonId</th>\n",
       "      <th>Title</th>\n",
       "      <th>Abstract</th>\n",
       "      <th>Lesson</th>\n",
       "      <th>Organization</th>\n",
       "      <th>LessonDate</th>\n",
       "      <th>MissionDirectorate</th>\n",
       "      <th>Categories</th>\n",
       "      <th>DocNum</th>\n",
       "      <th>Topic</th>\n",
       "      <th>Category</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SafetyIssue</th>\n",
       "      <th>Submitter1</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"30\" valign=\"top\">False</th>\n",
       "      <th>Acord, A</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Amundsen, Ruth</th>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Archer, Eric</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Artrip, Chris</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Atkins, K</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Atkins, Kenneth</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Axsom, Bob</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Backman, Charles</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Badalich, John</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Baggs, Ellis</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Baisley, R</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Baker, Gena</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Barnes, Robert</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bastedo, W</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Beifeld, David</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bell, Michael</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bennett, Richard</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Berry, Richard</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bishop, D</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Blaser, Carl</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Blosiu, J</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bodie, C</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bond, Rebecca</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bonine, Lisa</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Booher, Rebecca</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bopp, Charles</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bott, J</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bowling, Gordon</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Boyles, Mark</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Briceno, Anthony</th>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"30\" valign=\"top\">True</th>\n",
       "      <th>Nunnelee, Mark</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Oberhettinger, D</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Oberhettinger, David</th>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>24</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>22</td>\n",
       "      <td>18</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>18</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ochs, Bill</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Owens, Jerry</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Palmer, Jenni</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Palmieri, Diane</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Piasecki, Gerald</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pitt, Annette</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pitt, Marie</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Platt, Marilyn</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Porter, Amber</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Roberts, J</th>\n",
       "      <td>33</td>\n",
       "      <td>33</td>\n",
       "      <td>33</td>\n",
       "      <td>33</td>\n",
       "      <td>33</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ruiz, Robert</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Savino, J</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Schaper, P</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Shain, T</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stambolian, Damon</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stowes, Angela</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sunada, Eric</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Taylor, Jim</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Toberman, Michael</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tyler, S</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unknown</th>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>12</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Vaughan, William</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Vernier, Robert</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wagoner, B</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Welch, Ron</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Winterlin, Ronald</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wong, Richard</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>397 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   LessonId  Title  Abstract  Lesson  \\\n",
       "SafetyIssue Submitter1                                                 \n",
       "False       Acord, A                      2      2         2       2   \n",
       "            Amundsen, Ruth               15     15         0      15   \n",
       "            Archer, Eric                  1      1         1       1   \n",
       "            Artrip, Chris                 1      1         0       1   \n",
       "            Atkins, K                     1      1         1       1   \n",
       "            Atkins, Kenneth               1      1         1       1   \n",
       "            Axsom, Bob                    1      1         0       1   \n",
       "            Backman, Charles              1      1         0       1   \n",
       "            Badalich, John                1      1         0       1   \n",
       "            Baggs, Ellis                  4      4         0       4   \n",
       "            Baisley, R                    1      1         1       1   \n",
       "            Baker, Gena                   3      3         0       3   \n",
       "            Barnes, Robert                1      1         1       1   \n",
       "            Bastedo, W                    1      1         0       1   \n",
       "            Beifeld, David                1      1         1       1   \n",
       "            Bell, Michael                 6      6         6       6   \n",
       "            Bennett, Richard              1      1         1       1   \n",
       "            Berry, Richard                1      1         0       1   \n",
       "            Bishop, D                     1      1         0       1   \n",
       "            Blaser, Carl                  1      1         1       1   \n",
       "            Blosiu, J                     2      2         2       2   \n",
       "            Bodie, C                      1      1         1       1   \n",
       "            Bond, Rebecca                 1      1         1       1   \n",
       "            Bonine, Lisa                  1      1         1       1   \n",
       "            Booher, Rebecca               1      1         1       1   \n",
       "            Bopp, Charles                 1      1         0       1   \n",
       "            Bott, J                       2      2         2       2   \n",
       "            Bowling, Gordon               1      1         0       1   \n",
       "            Boyles, Mark                  2      2         2       2   \n",
       "            Briceno, Anthony             12     12         0      12   \n",
       "...                                     ...    ...       ...     ...   \n",
       "True        Nunnelee, Mark                1      1         1       1   \n",
       "            Oberhettinger, D              2      2         2       2   \n",
       "            Oberhettinger, David         25     25        24      25   \n",
       "            Ochs, Bill                    1      1         0       1   \n",
       "            Owens, Jerry                  1      1         1       1   \n",
       "            Palmer, Jenni                 1      1         1       1   \n",
       "            Palmieri, Diane               1      1         1       1   \n",
       "            Piasecki, Gerald              1      1         1       1   \n",
       "            Pitt, Annette                 4      4         4       4   \n",
       "            Pitt, Marie                   2      2         2       2   \n",
       "            Platt, Marilyn                1      1         1       1   \n",
       "            Porter, Amber                 7      7         7       7   \n",
       "            Roberts, J                   33     33        33      33   \n",
       "            Ruiz, Robert                  1      1         1       1   \n",
       "            Savino, J                     2      2         2       2   \n",
       "            Schaper, P                    2      2         2       2   \n",
       "            Shain, T                      1      1         1       1   \n",
       "            Stambolian, Damon             1      1         1       1   \n",
       "            Stowes, Angela                1      1         1       1   \n",
       "            Sunada, Eric                  1      1         0       1   \n",
       "            Taylor, Jim                   9      9         9       9   \n",
       "            Toberman, Michael             2      2         2       2   \n",
       "            Tyler, S                      1      1         1       1   \n",
       "            Unknown                      14     14        14      14   \n",
       "            Vaughan, William              1      1         1       1   \n",
       "            Vernier, Robert               1      1         1       1   \n",
       "            Wagoner, B                    2      2         2       2   \n",
       "            Welch, Ron                    1      1         1       1   \n",
       "            Winterlin, Ronald             6      6         6       6   \n",
       "            Wong, Richard                 1      1         1       1   \n",
       "\n",
       "                                   Organization  LessonDate  \\\n",
       "SafetyIssue Submitter1                                        \n",
       "False       Acord, A                          2           2   \n",
       "            Amundsen, Ruth                   15          15   \n",
       "            Archer, Eric                      1           1   \n",
       "            Artrip, Chris                     1           1   \n",
       "            Atkins, K                         1           1   \n",
       "            Atkins, Kenneth                   1           1   \n",
       "            Axsom, Bob                        1           1   \n",
       "            Backman, Charles                  1           1   \n",
       "            Badalich, John                    1           1   \n",
       "            Baggs, Ellis                      4           4   \n",
       "            Baisley, R                        1           1   \n",
       "            Baker, Gena                       3           3   \n",
       "            Barnes, Robert                    1           1   \n",
       "            Bastedo, W                        1           1   \n",
       "            Beifeld, David                    1           1   \n",
       "            Bell, Michael                     6           6   \n",
       "            Bennett, Richard                  1           1   \n",
       "            Berry, Richard                    1           1   \n",
       "            Bishop, D                         1           1   \n",
       "            Blaser, Carl                      1           1   \n",
       "            Blosiu, J                         2           2   \n",
       "            Bodie, C                          1           1   \n",
       "            Bond, Rebecca                     1           1   \n",
       "            Bonine, Lisa                      1           1   \n",
       "            Booher, Rebecca                   1           1   \n",
       "            Bopp, Charles                     1           1   \n",
       "            Bott, J                           2           2   \n",
       "            Bowling, Gordon                   1           1   \n",
       "            Boyles, Mark                      2           2   \n",
       "            Briceno, Anthony                 12          12   \n",
       "...                                         ...         ...   \n",
       "True        Nunnelee, Mark                    1           1   \n",
       "            Oberhettinger, D                  2           2   \n",
       "            Oberhettinger, David             25          25   \n",
       "            Ochs, Bill                        1           1   \n",
       "            Owens, Jerry                      1           1   \n",
       "            Palmer, Jenni                     1           1   \n",
       "            Palmieri, Diane                   1           1   \n",
       "            Piasecki, Gerald                  1           1   \n",
       "            Pitt, Annette                     4           4   \n",
       "            Pitt, Marie                       2           2   \n",
       "            Platt, Marilyn                    1           1   \n",
       "            Porter, Amber                     7           7   \n",
       "            Roberts, J                       33          33   \n",
       "            Ruiz, Robert                      1           1   \n",
       "            Savino, J                         2           2   \n",
       "            Schaper, P                        2           2   \n",
       "            Shain, T                          1           1   \n",
       "            Stambolian, Damon                 1           1   \n",
       "            Stowes, Angela                    1           1   \n",
       "            Sunada, Eric                      1           1   \n",
       "            Taylor, Jim                       9           9   \n",
       "            Toberman, Michael                 2           2   \n",
       "            Tyler, S                          1           1   \n",
       "            Unknown                          14          14   \n",
       "            Vaughan, William                  1           1   \n",
       "            Vernier, Robert                   1           1   \n",
       "            Wagoner, B                        2           2   \n",
       "            Welch, Ron                        1           1   \n",
       "            Winterlin, Ronald                 6           6   \n",
       "            Wong, Richard                     1           1   \n",
       "\n",
       "                                   MissionDirectorate  Categories  DocNum  \\\n",
       "SafetyIssue Submitter1                                                      \n",
       "False       Acord, A                                0           0       2   \n",
       "            Amundsen, Ruth                          0           0      15   \n",
       "            Archer, Eric                            1           0       1   \n",
       "            Artrip, Chris                           0           0       1   \n",
       "            Atkins, K                               1           0       1   \n",
       "            Atkins, Kenneth                         1           1       1   \n",
       "            Axsom, Bob                              0           0       1   \n",
       "            Backman, Charles                        0           0       1   \n",
       "            Badalich, John                          0           0       1   \n",
       "            Baggs, Ellis                            0           0       4   \n",
       "            Baisley, R                              0           0       1   \n",
       "            Baker, Gena                             3           0       3   \n",
       "            Barnes, Robert                          1           0       1   \n",
       "            Bastedo, W                              0           0       1   \n",
       "            Beifeld, David                          1           1       1   \n",
       "            Bell, Michael                           3           5       6   \n",
       "            Bennett, Richard                        1           0       1   \n",
       "            Berry, Richard                          1           0       1   \n",
       "            Bishop, D                               0           0       1   \n",
       "            Blaser, Carl                            1           1       1   \n",
       "            Blosiu, J                               0           0       2   \n",
       "            Bodie, C                                1           0       1   \n",
       "            Bond, Rebecca                           0           1       1   \n",
       "            Bonine, Lisa                            1           0       1   \n",
       "            Booher, Rebecca                         0           1       1   \n",
       "            Bopp, Charles                           0           0       1   \n",
       "            Bott, J                                 0           0       2   \n",
       "            Bowling, Gordon                         1           0       1   \n",
       "            Boyles, Mark                            2           0       2   \n",
       "            Briceno, Anthony                       12           0      12   \n",
       "...                                               ...         ...     ...   \n",
       "True        Nunnelee, Mark                          1           0       1   \n",
       "            Oberhettinger, D                        1           0       2   \n",
       "            Oberhettinger, David                   22          18      25   \n",
       "            Ochs, Bill                              1           0       1   \n",
       "            Owens, Jerry                            1           1       1   \n",
       "            Palmer, Jenni                           1           1       1   \n",
       "            Palmieri, Diane                         1           1       1   \n",
       "            Piasecki, Gerald                        1           1       1   \n",
       "            Pitt, Annette                           2           2       4   \n",
       "            Pitt, Marie                             2           2       2   \n",
       "            Platt, Marilyn                          1           0       1   \n",
       "            Porter, Amber                           0           7       7   \n",
       "            Roberts, J                              1           0      33   \n",
       "            Ruiz, Robert                            0           1       1   \n",
       "            Savino, J                               1           0       2   \n",
       "            Schaper, P                              0           0       2   \n",
       "            Shain, T                                0           0       1   \n",
       "            Stambolian, Damon                       0           1       1   \n",
       "            Stowes, Angela                          0           1       1   \n",
       "            Sunada, Eric                            1           0       1   \n",
       "            Taylor, Jim                             0           0       9   \n",
       "            Toberman, Michael                       2           0       2   \n",
       "            Tyler, S                                0           0       1   \n",
       "            Unknown                                12          14      14   \n",
       "            Vaughan, William                        1           0       1   \n",
       "            Vernier, Robert                         1           1       1   \n",
       "            Wagoner, B                              1           0       2   \n",
       "            Welch, Ron                              1           0       1   \n",
       "            Winterlin, Ronald                       6           0       6   \n",
       "            Wong, Richard                           1           0       1   \n",
       "\n",
       "                                   Topic  Category  url  \n",
       "SafetyIssue Submitter1                                   \n",
       "False       Acord, A                   2         0    2  \n",
       "            Amundsen, Ruth            15         0   15  \n",
       "            Archer, Eric               1         0    1  \n",
       "            Artrip, Chris              1         0    1  \n",
       "            Atkins, K                  1         0    1  \n",
       "            Atkins, Kenneth            1         1    1  \n",
       "            Axsom, Bob                 1         0    1  \n",
       "            Backman, Charles           1         0    1  \n",
       "            Badalich, John             1         0    1  \n",
       "            Baggs, Ellis               4         0    4  \n",
       "            Baisley, R                 1         0    1  \n",
       "            Baker, Gena                3         0    3  \n",
       "            Barnes, Robert             1         0    1  \n",
       "            Bastedo, W                 1         0    1  \n",
       "            Beifeld, David             1         1    1  \n",
       "            Bell, Michael              6         5    6  \n",
       "            Bennett, Richard           1         0    1  \n",
       "            Berry, Richard             1         0    1  \n",
       "            Bishop, D                  1         0    1  \n",
       "            Blaser, Carl               1         1    1  \n",
       "            Blosiu, J                  2         0    2  \n",
       "            Bodie, C                   1         0    1  \n",
       "            Bond, Rebecca              1         1    1  \n",
       "            Bonine, Lisa               1         0    1  \n",
       "            Booher, Rebecca            1         1    1  \n",
       "            Bopp, Charles              1         0    1  \n",
       "            Bott, J                    2         0    2  \n",
       "            Bowling, Gordon            1         0    1  \n",
       "            Boyles, Mark               2         0    2  \n",
       "            Briceno, Anthony          12         0   12  \n",
       "...                                  ...       ...  ...  \n",
       "True        Nunnelee, Mark             1         0    1  \n",
       "            Oberhettinger, D           2         0    2  \n",
       "            Oberhettinger, David      25        18   25  \n",
       "            Ochs, Bill                 1         0    1  \n",
       "            Owens, Jerry               1         1    1  \n",
       "            Palmer, Jenni              1         1    1  \n",
       "            Palmieri, Diane            1         1    1  \n",
       "            Piasecki, Gerald           1         1    1  \n",
       "            Pitt, Annette              4         2    4  \n",
       "            Pitt, Marie                2         2    2  \n",
       "            Platt, Marilyn             1         0    1  \n",
       "            Porter, Amber              7         7    7  \n",
       "            Roberts, J                33         0   33  \n",
       "            Ruiz, Robert               1         1    1  \n",
       "            Savino, J                  2         0    2  \n",
       "            Schaper, P                 2         0    2  \n",
       "            Shain, T                   1         0    1  \n",
       "            Stambolian, Damon          1         1    1  \n",
       "            Stowes, Angela             1         1    1  \n",
       "            Sunada, Eric               1         0    1  \n",
       "            Taylor, Jim                9         0    9  \n",
       "            Toberman, Michael          2         0    2  \n",
       "            Tyler, S                   1         0    1  \n",
       "            Unknown                   14        14   14  \n",
       "            Vaughan, William           1         0    1  \n",
       "            Vernier, Robert            1         1    1  \n",
       "            Wagoner, B                 2         0    2  \n",
       "            Welch, Ron                 1         0    1  \n",
       "            Winterlin, Ronald          6         0    6  \n",
       "            Wong, Richard              1         0    1  \n",
       "\n",
       "[397 rows x 12 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(['SafetyIssue','Submitter1']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1637"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "366"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submitter = df.sort_values(by=['Submitter1']).groupby(['Submitter1']).count()\n",
    "len(submitter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0               Bell, michael\n",
       "1              Bell, michael \n",
       "2       Oberhettinger, david \n",
       "3              Bell, michael \n",
       "4       Oberhettinger, david \n",
       "5                     Unknown\n",
       "6       Oberhettinger, david \n",
       "7       Oberhettinger, david \n",
       "8       Oberhettinger, david \n",
       "9                   Le, minh \n",
       "10          Pengra, patricia \n",
       "11                    Unknown\n",
       "12                    Unknown\n",
       "13                  Le, minh \n",
       "14              Hull, donald \n",
       "15              Hull, donald \n",
       "16             Laws, richard \n",
       "17                    Unknown\n",
       "18                  Le, minh \n",
       "19              Hull, donald \n",
       "20                  Le, minh \n",
       "21                    Unknown\n",
       "22                    Unknown\n",
       "23                    Unknown\n",
       "24         Stevens, jennifer \n",
       "25                    Unknown\n",
       "26                    Unknown\n",
       "27                    Unknown\n",
       "28                    Unknown\n",
       "29                    Unknown\n",
       "                ...          \n",
       "1607       Pennington, david \n",
       "1608       Pennington, david \n",
       "1609             Cockrell, c \n",
       "1610          Musgrave, lisa \n",
       "1611       Pennington, david \n",
       "1612          Musgrave, lisa \n",
       "1613          Musgrave, lisa \n",
       "1614       Pennington, david \n",
       "1615       Pennington, david \n",
       "1616       Pennington, david \n",
       "1617          Musgrave, lisa \n",
       "1618          Musgrave, lisa \n",
       "1619          Musgrave, lisa \n",
       "1620          Musgrave, lisa \n",
       "1621          Musgrave, lisa \n",
       "1622       Pennington, david \n",
       "1623       Pennington, david \n",
       "1624       Pennington, david \n",
       "1625       Pennington, david \n",
       "1626       Pennington, david \n",
       "1627          Musgrave, lisa \n",
       "1628       Pennington, david \n",
       "1629       Pennington, david \n",
       "1630          Musgrave, lisa \n",
       "1631               Holden, w \n",
       "1632       Pennington, david \n",
       "1633              Seiwell, r \n",
       "1634           Carrol, donna \n",
       "1635            Underwood, l \n",
       "1636             Sullivan, j \n",
       "Name: Submitter1, Length: 1637, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Submitter1'].str.capitalize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0               BELL, MICHAEL\n",
       "1              BELL, MICHAEL \n",
       "2       OBERHETTINGER, DAVID \n",
       "3              BELL, MICHAEL \n",
       "4       OBERHETTINGER, DAVID \n",
       "5                     UNKNOWN\n",
       "6       OBERHETTINGER, DAVID \n",
       "7       OBERHETTINGER, DAVID \n",
       "8       OBERHETTINGER, DAVID \n",
       "9                   LE, MINH \n",
       "10          PENGRA, PATRICIA \n",
       "11                    UNKNOWN\n",
       "12                    UNKNOWN\n",
       "13                  LE, MINH \n",
       "14              HULL, DONALD \n",
       "15              HULL, DONALD \n",
       "16             LAWS, RICHARD \n",
       "17                    UNKNOWN\n",
       "18                  LE, MINH \n",
       "19              HULL, DONALD \n",
       "20                  LE, MINH \n",
       "21                    UNKNOWN\n",
       "22                    UNKNOWN\n",
       "23                    UNKNOWN\n",
       "24         STEVENS, JENNIFER \n",
       "25                    UNKNOWN\n",
       "26                    UNKNOWN\n",
       "27                    UNKNOWN\n",
       "28                    UNKNOWN\n",
       "29                    UNKNOWN\n",
       "                ...          \n",
       "1607       PENNINGTON, DAVID \n",
       "1608       PENNINGTON, DAVID \n",
       "1609             COCKRELL, C \n",
       "1610          MUSGRAVE, LISA \n",
       "1611       PENNINGTON, DAVID \n",
       "1612          MUSGRAVE, LISA \n",
       "1613          MUSGRAVE, LISA \n",
       "1614       PENNINGTON, DAVID \n",
       "1615       PENNINGTON, DAVID \n",
       "1616       PENNINGTON, DAVID \n",
       "1617          MUSGRAVE, LISA \n",
       "1618          MUSGRAVE, LISA \n",
       "1619          MUSGRAVE, LISA \n",
       "1620          MUSGRAVE, LISA \n",
       "1621          MUSGRAVE, LISA \n",
       "1622       PENNINGTON, DAVID \n",
       "1623       PENNINGTON, DAVID \n",
       "1624       PENNINGTON, DAVID \n",
       "1625       PENNINGTON, DAVID \n",
       "1626       PENNINGTON, DAVID \n",
       "1627          MUSGRAVE, LISA \n",
       "1628       PENNINGTON, DAVID \n",
       "1629       PENNINGTON, DAVID \n",
       "1630          MUSGRAVE, LISA \n",
       "1631               HOLDEN, W \n",
       "1632       PENNINGTON, DAVID \n",
       "1633              SEIWELL, R \n",
       "1634           CARROL, DONNA \n",
       "1635            UNDERWOOD, L \n",
       "1636             SULLIVAN, J \n",
       "Name: Submitter1, Length: 1637, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Submitter1'].apply(lambda x: x.upper())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "366"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submitter = df.sort_values(by=['Submitter1']).groupby(['Submitter1']).count()\n",
    "len(submitter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove trailing spaces at end or beginning\n",
    "df['Submitter1'] = df['Submitter1'].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "365"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submitter = df.sort_values(by=['Submitter1']).groupby(['Submitter1']).count()\n",
    "len(submitter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['name_last','name_first']] = df['Submitter1'].str.split(',',expand=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LessonId</th>\n",
       "      <th>Submitter1</th>\n",
       "      <th>Title</th>\n",
       "      <th>Abstract</th>\n",
       "      <th>Lesson</th>\n",
       "      <th>Organization</th>\n",
       "      <th>LessonDate</th>\n",
       "      <th>MissionDirectorate</th>\n",
       "      <th>SafetyIssue</th>\n",
       "      <th>Categories</th>\n",
       "      <th>DocNum</th>\n",
       "      <th>Topic</th>\n",
       "      <th>Category</th>\n",
       "      <th>url</th>\n",
       "      <th>name_last</th>\n",
       "      <th>name_first</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9501</td>\n",
       "      <td>Bell, Michael</td>\n",
       "      <td>Manhole Arc-Flash Risk Reduction</td>\n",
       "      <td>Power system distribution at Kennedy Space C...</td>\n",
       "      <td>Laboratory testing revealed higher than anti...</td>\n",
       "      <td>KSC</td>\n",
       "      <td>6/6/14</td>\n",
       "      <td>Aeronautics Research, Human Exploration and Op...</td>\n",
       "      <td>True</td>\n",
       "      <td>Energy, Facilities, Industrial Operations, Per...</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>Energy</td>\n",
       "      <td>https://nen.nasa.gov/web/11/viewall/-/viewall/...</td>\n",
       "      <td>Bell</td>\n",
       "      <td>Michael</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8018</td>\n",
       "      <td>Bell, Michael</td>\n",
       "      <td>CRCA Sampling Process Lessons Learned</td>\n",
       "      <td>The sampling and analysis processes, used to...</td>\n",
       "      <td>The particle contamination monitoring was in...</td>\n",
       "      <td>KSC</td>\n",
       "      <td>3/11/14</td>\n",
       "      <td>Human Exploration and Operations,</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://nen.nasa.gov/web/11/viewall/-/viewall/...</td>\n",
       "      <td>Bell</td>\n",
       "      <td>Michael</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8701</td>\n",
       "      <td>Oberhettinger, David</td>\n",
       "      <td>Take Special Care to Avoid Misprobing When Usi...</td>\n",
       "      <td>An operator error involving mis-probing duri...</td>\n",
       "      <td>The common use of BOBs during subsystem/syst...</td>\n",
       "      <td>JPL</td>\n",
       "      <td>2/18/14</td>\n",
       "      <td>Aeronautics Research, Human Exploration and Op...</td>\n",
       "      <td>True</td>\n",
       "      <td>Integration and Testing, Safety and Mission As...</td>\n",
       "      <td>3</td>\n",
       "      <td>31</td>\n",
       "      <td>Integration and Testing</td>\n",
       "      <td>https://nen.nasa.gov/web/11/viewall/-/viewall/...</td>\n",
       "      <td>Oberhettinger</td>\n",
       "      <td>David</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   LessonId            Submitter1  \\\n",
       "0      9501         Bell, Michael   \n",
       "1      8018         Bell, Michael   \n",
       "2      8701  Oberhettinger, David   \n",
       "\n",
       "                                               Title  \\\n",
       "0                   Manhole Arc-Flash Risk Reduction   \n",
       "1              CRCA Sampling Process Lessons Learned   \n",
       "2  Take Special Care to Avoid Misprobing When Usi...   \n",
       "\n",
       "                                            Abstract  \\\n",
       "0    Power system distribution at Kennedy Space C...   \n",
       "1    The sampling and analysis processes, used to...   \n",
       "2    An operator error involving mis-probing duri...   \n",
       "\n",
       "                                              Lesson Organization LessonDate  \\\n",
       "0    Laboratory testing revealed higher than anti...          KSC     6/6/14   \n",
       "1    The particle contamination monitoring was in...          KSC    3/11/14   \n",
       "2    The common use of BOBs during subsystem/syst...          JPL    2/18/14   \n",
       "\n",
       "                                  MissionDirectorate  SafetyIssue  \\\n",
       "0  Aeronautics Research, Human Exploration and Op...         True   \n",
       "1                 Human Exploration and Operations,         False   \n",
       "2  Aeronautics Research, Human Exploration and Op...         True   \n",
       "\n",
       "                                          Categories  DocNum  Topic  \\\n",
       "0  Energy, Facilities, Industrial Operations, Per...       1     22   \n",
       "1                                                NaN       2     18   \n",
       "2  Integration and Testing, Safety and Mission As...       3     31   \n",
       "\n",
       "                  Category                                                url  \\\n",
       "0                   Energy  https://nen.nasa.gov/web/11/viewall/-/viewall/...   \n",
       "1                      NaN  https://nen.nasa.gov/web/11/viewall/-/viewall/...   \n",
       "2  Integration and Testing  https://nen.nasa.gov/web/11/viewall/-/viewall/...   \n",
       "\n",
       "       name_last name_first  \n",
       "0           Bell    Michael  \n",
       "1           Bell    Michael  \n",
       "2  Oberhettinger      David  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                Bell\n",
       "1                Bell\n",
       "2       Oberhettinger\n",
       "3                Bell\n",
       "4       Oberhettinger\n",
       "5             Unknown\n",
       "6       Oberhettinger\n",
       "7       Oberhettinger\n",
       "8       Oberhettinger\n",
       "9                  Le\n",
       "10             Pengra\n",
       "11            Unknown\n",
       "12            Unknown\n",
       "13                 Le\n",
       "14               Hull\n",
       "15               Hull\n",
       "16               Laws\n",
       "17            Unknown\n",
       "18                 Le\n",
       "19               Hull\n",
       "20                 Le\n",
       "21            Unknown\n",
       "22            Unknown\n",
       "23            Unknown\n",
       "24            Stevens\n",
       "25            Unknown\n",
       "26            Unknown\n",
       "27            Unknown\n",
       "28            Unknown\n",
       "29            Unknown\n",
       "            ...      \n",
       "1607       Pennington\n",
       "1608       Pennington\n",
       "1609         Cockrell\n",
       "1610         Musgrave\n",
       "1611       Pennington\n",
       "1612         Musgrave\n",
       "1613         Musgrave\n",
       "1614       Pennington\n",
       "1615       Pennington\n",
       "1616       Pennington\n",
       "1617         Musgrave\n",
       "1618         Musgrave\n",
       "1619         Musgrave\n",
       "1620         Musgrave\n",
       "1621         Musgrave\n",
       "1622       Pennington\n",
       "1623       Pennington\n",
       "1624       Pennington\n",
       "1625       Pennington\n",
       "1626       Pennington\n",
       "1627         Musgrave\n",
       "1628       Pennington\n",
       "1629       Pennington\n",
       "1630         Musgrave\n",
       "1631           Holden\n",
       "1632       Pennington\n",
       "1633          Seiwell\n",
       "1634           Carrol\n",
       "1635        Underwood\n",
       "1636         Sullivan\n",
       "Name: name_last, Length: 1637, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['name_last'].str.capitalize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LessonId</th>\n",
       "      <th>Submitter1</th>\n",
       "      <th>Title</th>\n",
       "      <th>Abstract</th>\n",
       "      <th>Lesson</th>\n",
       "      <th>Organization</th>\n",
       "      <th>LessonDate</th>\n",
       "      <th>MissionDirectorate</th>\n",
       "      <th>SafetyIssue</th>\n",
       "      <th>Categories</th>\n",
       "      <th>DocNum</th>\n",
       "      <th>Topic</th>\n",
       "      <th>Category</th>\n",
       "      <th>url</th>\n",
       "      <th>name_last</th>\n",
       "      <th>name_first</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1617</th>\n",
       "      <td>139</td>\n",
       "      <td>Musgrave, Lisa</td>\n",
       "      <td>Postlanding Orbiter Compartment Vapor Sampling</td>\n",
       "      <td>NaN</td>\n",
       "      <td>An undetected accumulation of toxic/flammable...</td>\n",
       "      <td>KSC</td>\n",
       "      <td>10/5/92</td>\n",
       "      <td>Exploration Systems, Space Operations,</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1859</td>\n",
       "      <td>35</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://nen.nasa.gov/web/11/viewall/-/viewall/139</td>\n",
       "      <td>Musgrave</td>\n",
       "      <td>Lisa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1618</th>\n",
       "      <td>143</td>\n",
       "      <td>Musgrave, Lisa</td>\n",
       "      <td>Engine Changeout Platform (ECP) and Engine Ser...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Failure of wire ropes, winch components, or o...</td>\n",
       "      <td>KSC</td>\n",
       "      <td>10/5/92</td>\n",
       "      <td>Exploration Systems, Space Operations,</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1860</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://nen.nasa.gov/web/11/viewall/-/viewall/143</td>\n",
       "      <td>Musgrave</td>\n",
       "      <td>Lisa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1619</th>\n",
       "      <td>142</td>\n",
       "      <td>Musgrave, Lisa</td>\n",
       "      <td>540A Industrial Oxygen (O2) Analyzer Monitoring</td>\n",
       "      <td>NaN</td>\n",
       "      <td>An oxygen analyzer system failure may cause p...</td>\n",
       "      <td>KSC</td>\n",
       "      <td>10/5/92</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1861</td>\n",
       "      <td>26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://nen.nasa.gov/web/11/viewall/-/viewall/142</td>\n",
       "      <td>Musgrave</td>\n",
       "      <td>Lisa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1620</th>\n",
       "      <td>141</td>\n",
       "      <td>Musgrave, Lisa</td>\n",
       "      <td>Radioisotope Thermoelectric Generator Facility...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Failure of the RTGF crane electrical componen...</td>\n",
       "      <td>KSC</td>\n",
       "      <td>10/5/92</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1862</td>\n",
       "      <td>33</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://nen.nasa.gov/web/11/viewall/-/viewall/141</td>\n",
       "      <td>Musgrave</td>\n",
       "      <td>Lisa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1621</th>\n",
       "      <td>140</td>\n",
       "      <td>Musgrave, Lisa</td>\n",
       "      <td>Suspended Load Operations</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Failure of a critical item lifting device (cr...</td>\n",
       "      <td>KSC</td>\n",
       "      <td>10/5/92</td>\n",
       "      <td>Exploration Systems, Space Operations,</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1863</td>\n",
       "      <td>33</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://nen.nasa.gov/web/11/viewall/-/viewall/140</td>\n",
       "      <td>Musgrave</td>\n",
       "      <td>Lisa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1622</th>\n",
       "      <td>146</td>\n",
       "      <td>Pennington, David</td>\n",
       "      <td>Fuel and Oxidizer Storage Tank Relief Valves.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Lack of relief valve isolation has resulted i...</td>\n",
       "      <td>KSC</td>\n",
       "      <td>10/2/92</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1864</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://nen.nasa.gov/web/11/viewall/-/viewall/146</td>\n",
       "      <td>Pennington</td>\n",
       "      <td>David</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1623</th>\n",
       "      <td>133</td>\n",
       "      <td>Pennington, David</td>\n",
       "      <td>Orbiter Avionics System.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cooling system flexhoses that supply the orbi...</td>\n",
       "      <td>KSC</td>\n",
       "      <td>9/24/92</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1876</td>\n",
       "      <td>31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://nen.nasa.gov/web/11/viewall/-/viewall/133</td>\n",
       "      <td>Pennington</td>\n",
       "      <td>David</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1624</th>\n",
       "      <td>39</td>\n",
       "      <td>Pennington, David</td>\n",
       "      <td>SSME Oxygen Lines</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Helium leak detector roughing pump failure du...</td>\n",
       "      <td>KSC</td>\n",
       "      <td>9/18/92</td>\n",
       "      <td>Exploration Systems, Space Operations,</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1878</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://nen.nasa.gov/web/11/viewall/-/viewall/39</td>\n",
       "      <td>Pennington</td>\n",
       "      <td>David</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1625</th>\n",
       "      <td>38</td>\n",
       "      <td>Pennington, David</td>\n",
       "      <td>Undetected GH2 Release in the OPF</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Failure to establish controlled venting of PR...</td>\n",
       "      <td>KSC</td>\n",
       "      <td>9/18/92</td>\n",
       "      <td>Exploration Systems, Space Operations,</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1879</td>\n",
       "      <td>27</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://nen.nasa.gov/web/11/viewall/-/viewall/38</td>\n",
       "      <td>Pennington</td>\n",
       "      <td>David</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1626</th>\n",
       "      <td>111</td>\n",
       "      <td>Pennington, David</td>\n",
       "      <td>LH2 Quick Disconnects (QD)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Quick disconnects utilized for providing gass...</td>\n",
       "      <td>KSC</td>\n",
       "      <td>8/27/92</td>\n",
       "      <td>Exploration Systems, Space Operations,</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1896</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://nen.nasa.gov/web/11/viewall/-/viewall/111</td>\n",
       "      <td>Pennington</td>\n",
       "      <td>David</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1627</th>\n",
       "      <td>120</td>\n",
       "      <td>Musgrave, Lisa</td>\n",
       "      <td>Liquid Tanker (LT) Liquid Level Indicator (LLI...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\\n\\n        Shocks/vibrations induced into a...</td>\n",
       "      <td>KSC</td>\n",
       "      <td>8/12/92</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1916</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://nen.nasa.gov/web/11/viewall/-/viewall/120</td>\n",
       "      <td>Musgrave</td>\n",
       "      <td>Lisa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1628</th>\n",
       "      <td>102</td>\n",
       "      <td>Pennington, David</td>\n",
       "      <td>High Pressure Shutoff Valves; Vacuum Pump Isol...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\\n\\n        Failure to establish a preventat...</td>\n",
       "      <td>KSC</td>\n",
       "      <td>8/11/92</td>\n",
       "      <td>Aeronautics Research, Science, Exploration Sys...</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1917</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://nen.nasa.gov/web/11/viewall/-/viewall/102</td>\n",
       "      <td>Pennington</td>\n",
       "      <td>David</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1629</th>\n",
       "      <td>101</td>\n",
       "      <td>Pennington, David</td>\n",
       "      <td>Proof Load Test Fixture</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Lack of a safety cut-out switch on the proof ...</td>\n",
       "      <td>KSC</td>\n",
       "      <td>8/10/92</td>\n",
       "      <td>Aeronautics Research, Science, Exploration Sys...</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1918</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://nen.nasa.gov/web/11/viewall/-/viewall/101</td>\n",
       "      <td>Pennington</td>\n",
       "      <td>David</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1630</th>\n",
       "      <td>119</td>\n",
       "      <td>Musgrave, Lisa</td>\n",
       "      <td>Solid Rocket Motor (SRM) Segment and Handling ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\\n\\n        Documentation lacking cross refe...</td>\n",
       "      <td>KSC</td>\n",
       "      <td>8/10/92</td>\n",
       "      <td>Exploration Systems, Space Operations,</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1919</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://nen.nasa.gov/web/11/viewall/-/viewall/119</td>\n",
       "      <td>Musgrave</td>\n",
       "      <td>Lisa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1631</th>\n",
       "      <td>1186</td>\n",
       "      <td>Holden, W</td>\n",
       "      <td>Railroad Maintenance Contractor Boom Crane Mis...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>It is the opinion of this mishap investigatio...</td>\n",
       "      <td>KSC</td>\n",
       "      <td>4/9/92</td>\n",
       "      <td>Exploration Systems, Space Operations,</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1956</td>\n",
       "      <td>35</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://nen.nasa.gov/web/11/viewall/-/viewall/...</td>\n",
       "      <td>Holden</td>\n",
       "      <td>W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1632</th>\n",
       "      <td>51</td>\n",
       "      <td>Pennington, David</td>\n",
       "      <td>Dry Well Transducer Installations are Suscepti...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\\n\\n        Adequate physical safeguards do ...</td>\n",
       "      <td>KSC</td>\n",
       "      <td>12/27/91</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1976</td>\n",
       "      <td>27</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://nen.nasa.gov/web/11/viewall/-/viewall/51</td>\n",
       "      <td>Pennington</td>\n",
       "      <td>David</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1633</th>\n",
       "      <td>17</td>\n",
       "      <td>Seiwell, R</td>\n",
       "      <td>Shorted Wires (From Pinching by an Uninsulated...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A reassembly error (a dislocated wire pinched...</td>\n",
       "      <td>JSC</td>\n",
       "      <td>7/29/91</td>\n",
       "      <td>Aeronautics Research, Exploration Systems, Spa...</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1996</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://nen.nasa.gov/web/11/viewall/-/viewall/17</td>\n",
       "      <td>Seiwell</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1634</th>\n",
       "      <td>16</td>\n",
       "      <td>Carrol, Donna</td>\n",
       "      <td>Reversed Installation of a Check Valve Spring ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>An incorrect installation of a critical compo...</td>\n",
       "      <td>JSC</td>\n",
       "      <td>7/28/91</td>\n",
       "      <td>Aeronautics Research, Exploration Systems, Spa...</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1997</td>\n",
       "      <td>21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://nen.nasa.gov/web/11/viewall/-/viewall/16</td>\n",
       "      <td>Carrol</td>\n",
       "      <td>Donna</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1635</th>\n",
       "      <td>449</td>\n",
       "      <td>Underwood, L</td>\n",
       "      <td>Migration of Conductive Contaminates in an Ele...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Excess wear led to migration of conductive co...</td>\n",
       "      <td>JSC</td>\n",
       "      <td>12/15/90</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://nen.nasa.gov/web/11/viewall/-/viewall/449</td>\n",
       "      <td>Underwood</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1636</th>\n",
       "      <td>1199</td>\n",
       "      <td>Sullivan, J</td>\n",
       "      <td>OV-104 STS-38 Avionics Bay Platform Beam Assem...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The primary and major contributory causes of ...</td>\n",
       "      <td>KSC</td>\n",
       "      <td>9/3/90</td>\n",
       "      <td>Exploration Systems, Space Operations,</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://nen.nasa.gov/web/11/viewall/-/viewall/...</td>\n",
       "      <td>Sullivan</td>\n",
       "      <td>J</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      LessonId         Submitter1  \\\n",
       "1617       139     Musgrave, Lisa   \n",
       "1618       143     Musgrave, Lisa   \n",
       "1619       142     Musgrave, Lisa   \n",
       "1620       141     Musgrave, Lisa   \n",
       "1621       140     Musgrave, Lisa   \n",
       "1622       146  Pennington, David   \n",
       "1623       133  Pennington, David   \n",
       "1624        39  Pennington, David   \n",
       "1625        38  Pennington, David   \n",
       "1626       111  Pennington, David   \n",
       "1627       120     Musgrave, Lisa   \n",
       "1628       102  Pennington, David   \n",
       "1629       101  Pennington, David   \n",
       "1630       119     Musgrave, Lisa   \n",
       "1631      1186          Holden, W   \n",
       "1632        51  Pennington, David   \n",
       "1633        17         Seiwell, R   \n",
       "1634        16      Carrol, Donna   \n",
       "1635       449       Underwood, L   \n",
       "1636      1199        Sullivan, J   \n",
       "\n",
       "                                                  Title Abstract  \\\n",
       "1617     Postlanding Orbiter Compartment Vapor Sampling      NaN   \n",
       "1618  Engine Changeout Platform (ECP) and Engine Ser...      NaN   \n",
       "1619    540A Industrial Oxygen (O2) Analyzer Monitoring      NaN   \n",
       "1620  Radioisotope Thermoelectric Generator Facility...      NaN   \n",
       "1621                          Suspended Load Operations      NaN   \n",
       "1622      Fuel and Oxidizer Storage Tank Relief Valves.      NaN   \n",
       "1623                           Orbiter Avionics System.      NaN   \n",
       "1624                                  SSME Oxygen Lines      NaN   \n",
       "1625                  Undetected GH2 Release in the OPF      NaN   \n",
       "1626                         LH2 Quick Disconnects (QD)      NaN   \n",
       "1627  Liquid Tanker (LT) Liquid Level Indicator (LLI...      NaN   \n",
       "1628  High Pressure Shutoff Valves; Vacuum Pump Isol...      NaN   \n",
       "1629                            Proof Load Test Fixture      NaN   \n",
       "1630  Solid Rocket Motor (SRM) Segment and Handling ...      NaN   \n",
       "1631  Railroad Maintenance Contractor Boom Crane Mis...      NaN   \n",
       "1632  Dry Well Transducer Installations are Suscepti...      NaN   \n",
       "1633  Shorted Wires (From Pinching by an Uninsulated...      NaN   \n",
       "1634  Reversed Installation of a Check Valve Spring ...      NaN   \n",
       "1635  Migration of Conductive Contaminates in an Ele...      NaN   \n",
       "1636  OV-104 STS-38 Avionics Bay Platform Beam Assem...      NaN   \n",
       "\n",
       "                                                 Lesson Organization  \\\n",
       "1617   An undetected accumulation of toxic/flammable...          KSC   \n",
       "1618   Failure of wire ropes, winch components, or o...          KSC   \n",
       "1619   An oxygen analyzer system failure may cause p...          KSC   \n",
       "1620   Failure of the RTGF crane electrical componen...          KSC   \n",
       "1621   Failure of a critical item lifting device (cr...          KSC   \n",
       "1622   Lack of relief valve isolation has resulted i...          KSC   \n",
       "1623   Cooling system flexhoses that supply the orbi...          KSC   \n",
       "1624   Helium leak detector roughing pump failure du...          KSC   \n",
       "1625   Failure to establish controlled venting of PR...          KSC   \n",
       "1626   Quick disconnects utilized for providing gass...          KSC   \n",
       "1627    \\n\\n        Shocks/vibrations induced into a...          KSC   \n",
       "1628    \\n\\n        Failure to establish a preventat...          KSC   \n",
       "1629   Lack of a safety cut-out switch on the proof ...          KSC   \n",
       "1630    \\n\\n        Documentation lacking cross refe...          KSC   \n",
       "1631   It is the opinion of this mishap investigatio...          KSC   \n",
       "1632    \\n\\n        Adequate physical safeguards do ...          KSC   \n",
       "1633   A reassembly error (a dislocated wire pinched...          JSC   \n",
       "1634   An incorrect installation of a critical compo...          JSC   \n",
       "1635   Excess wear led to migration of conductive co...          JSC   \n",
       "1636   The primary and major contributory causes of ...          KSC   \n",
       "\n",
       "     LessonDate                                 MissionDirectorate  \\\n",
       "1617    10/5/92            Exploration Systems, Space Operations,    \n",
       "1618    10/5/92            Exploration Systems, Space Operations,    \n",
       "1619    10/5/92                                                NaN   \n",
       "1620    10/5/92                                                NaN   \n",
       "1621    10/5/92            Exploration Systems, Space Operations,    \n",
       "1622    10/2/92                                                NaN   \n",
       "1623    9/24/92                                                NaN   \n",
       "1624    9/18/92            Exploration Systems, Space Operations,    \n",
       "1625    9/18/92            Exploration Systems, Space Operations,    \n",
       "1626    8/27/92            Exploration Systems, Space Operations,    \n",
       "1627    8/12/92                                                NaN   \n",
       "1628    8/11/92  Aeronautics Research, Science, Exploration Sys...   \n",
       "1629    8/10/92  Aeronautics Research, Science, Exploration Sys...   \n",
       "1630    8/10/92            Exploration Systems, Space Operations,    \n",
       "1631     4/9/92            Exploration Systems, Space Operations,    \n",
       "1632   12/27/91                                                NaN   \n",
       "1633    7/29/91  Aeronautics Research, Exploration Systems, Spa...   \n",
       "1634    7/28/91  Aeronautics Research, Exploration Systems, Spa...   \n",
       "1635   12/15/90                                                NaN   \n",
       "1636     9/3/90            Exploration Systems, Space Operations,    \n",
       "\n",
       "      SafetyIssue Categories  DocNum  Topic Category  \\\n",
       "1617        False        NaN    1859     35      NaN   \n",
       "1618        False        NaN    1860     23      NaN   \n",
       "1619        False        NaN    1861     26      NaN   \n",
       "1620        False        NaN    1862     33      NaN   \n",
       "1621        False        NaN    1863     33      NaN   \n",
       "1622        False        NaN    1864      2      NaN   \n",
       "1623        False        NaN    1876     31      NaN   \n",
       "1624        False        NaN    1878      2      NaN   \n",
       "1625        False        NaN    1879     27      NaN   \n",
       "1626        False        NaN    1896      5      NaN   \n",
       "1627        False        NaN    1916      3      NaN   \n",
       "1628        False        NaN    1917      2      NaN   \n",
       "1629        False        NaN    1918      4      NaN   \n",
       "1630        False        NaN    1919     12      NaN   \n",
       "1631        False        NaN    1956     35      NaN   \n",
       "1632        False        NaN    1976     27      NaN   \n",
       "1633        False        NaN    1996      9      NaN   \n",
       "1634        False        NaN    1997     21      NaN   \n",
       "1635        False        NaN    2016     13      NaN   \n",
       "1636        False        NaN    2017     11      NaN   \n",
       "\n",
       "                                                    url   name_last name_first  \n",
       "1617  https://nen.nasa.gov/web/11/viewall/-/viewall/139    Musgrave       Lisa  \n",
       "1618  https://nen.nasa.gov/web/11/viewall/-/viewall/143    Musgrave       Lisa  \n",
       "1619  https://nen.nasa.gov/web/11/viewall/-/viewall/142    Musgrave       Lisa  \n",
       "1620  https://nen.nasa.gov/web/11/viewall/-/viewall/141    Musgrave       Lisa  \n",
       "1621  https://nen.nasa.gov/web/11/viewall/-/viewall/140    Musgrave       Lisa  \n",
       "1622  https://nen.nasa.gov/web/11/viewall/-/viewall/146  Pennington      David  \n",
       "1623  https://nen.nasa.gov/web/11/viewall/-/viewall/133  Pennington      David  \n",
       "1624   https://nen.nasa.gov/web/11/viewall/-/viewall/39  Pennington      David  \n",
       "1625   https://nen.nasa.gov/web/11/viewall/-/viewall/38  Pennington      David  \n",
       "1626  https://nen.nasa.gov/web/11/viewall/-/viewall/111  Pennington      David  \n",
       "1627  https://nen.nasa.gov/web/11/viewall/-/viewall/120    Musgrave       Lisa  \n",
       "1628  https://nen.nasa.gov/web/11/viewall/-/viewall/102  Pennington      David  \n",
       "1629  https://nen.nasa.gov/web/11/viewall/-/viewall/101  Pennington      David  \n",
       "1630  https://nen.nasa.gov/web/11/viewall/-/viewall/119    Musgrave       Lisa  \n",
       "1631  https://nen.nasa.gov/web/11/viewall/-/viewall/...      Holden          W  \n",
       "1632   https://nen.nasa.gov/web/11/viewall/-/viewall/51  Pennington      David  \n",
       "1633   https://nen.nasa.gov/web/11/viewall/-/viewall/17     Seiwell          R  \n",
       "1634   https://nen.nasa.gov/web/11/viewall/-/viewall/16      Carrol      Donna  \n",
       "1635  https://nen.nasa.gov/web/11/viewall/-/viewall/449   Underwood          L  \n",
       "1636  https://nen.nasa.gov/web/11/viewall/-/viewall/...    Sullivan          J  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "365"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name_first = df.sort_values(by=['name_first']).groupby(['name_first']).count()\n",
    "len(submitter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LessonId</th>\n",
       "      <th>Submitter1</th>\n",
       "      <th>Title</th>\n",
       "      <th>Abstract</th>\n",
       "      <th>Lesson</th>\n",
       "      <th>Organization</th>\n",
       "      <th>LessonDate</th>\n",
       "      <th>MissionDirectorate</th>\n",
       "      <th>SafetyIssue</th>\n",
       "      <th>Categories</th>\n",
       "      <th>DocNum</th>\n",
       "      <th>Topic</th>\n",
       "      <th>Category</th>\n",
       "      <th>url</th>\n",
       "      <th>name_last</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>name_first</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Al</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alan</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Albert</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alicia</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Allan</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Amber</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Andre</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Angela</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Annette</th>\n",
       "      <td>93</td>\n",
       "      <td>93</td>\n",
       "      <td>93</td>\n",
       "      <td>93</td>\n",
       "      <td>93</td>\n",
       "      <td>93</td>\n",
       "      <td>93</td>\n",
       "      <td>91</td>\n",
       "      <td>93</td>\n",
       "      <td>91</td>\n",
       "      <td>93</td>\n",
       "      <td>93</td>\n",
       "      <td>91</td>\n",
       "      <td>93</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Anthony</th>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Barbara</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Barrie</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bernard</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bill</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Billy</th>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bob</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bonita</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Brent</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Brian</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bryant</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C</th>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>14</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Calvert</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Carl</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Carol</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Case</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cecile</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Charles</th>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Chien</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Roger</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ron</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ronald</th>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>20</td>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>22</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Roy</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ruth</th>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ryan</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S</th>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Scott</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sean</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Shawn</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stephen</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Steve</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Steven</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Suong</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Susan</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Suzanne</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Thomas</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Thuykien</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Todd</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tom</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Trong</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Trudy</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>W</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wil</th>\n",
       "      <td>149</td>\n",
       "      <td>149</td>\n",
       "      <td>149</td>\n",
       "      <td>34</td>\n",
       "      <td>149</td>\n",
       "      <td>149</td>\n",
       "      <td>149</td>\n",
       "      <td>147</td>\n",
       "      <td>149</td>\n",
       "      <td>0</td>\n",
       "      <td>149</td>\n",
       "      <td>149</td>\n",
       "      <td>0</td>\n",
       "      <td>149</td>\n",
       "      <td>149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>William</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wilson</th>\n",
       "      <td>63</td>\n",
       "      <td>63</td>\n",
       "      <td>63</td>\n",
       "      <td>13</td>\n",
       "      <td>63</td>\n",
       "      <td>63</td>\n",
       "      <td>63</td>\n",
       "      <td>51</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Yvonne</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ave</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lisa</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>181 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            LessonId  Submitter1  Title  Abstract  Lesson  Organization  \\\n",
       "name_first                                                                \n",
       " A                 5           5      5         5       5             5   \n",
       " Al                1           1      1         1       1             1   \n",
       " Alan              1           1      1         0       1             1   \n",
       " Albert            2           2      2         1       2             2   \n",
       " Alicia            1           1      1         0       1             1   \n",
       " Allan             1           1      1         1       1             1   \n",
       " Amber             8           8      8         8       8             8   \n",
       " Andre             2           2      2         2       2             2   \n",
       " Angela            1           1      1         1       1             1   \n",
       " Annette          93          93     93        93      93            93   \n",
       " Anthony          12          12     12         0      12            12   \n",
       " B                10          10     10         9      10            10   \n",
       " Barbara           3           3      3         3       3             3   \n",
       " Barrie            1           1      1         1       1             1   \n",
       " Bernard           7           7      7         0       7             7   \n",
       " Bill              6           6      6         2       6             6   \n",
       " Billy            17          17     17         0      17            17   \n",
       " Bob               1           1      1         0       1             1   \n",
       " Bonita            8           8      8         0       8             8   \n",
       " Brent             1           1      1         1       1             1   \n",
       " Brian             1           1      1         0       1             1   \n",
       " Bryant            1           1      1         0       1             1   \n",
       " C                16          16     16        14      16            16   \n",
       " Calvert           1           1      1         0       1             1   \n",
       " Carl              2           2      2         1       2             2   \n",
       " Carol             3           3      3         2       3             3   \n",
       " Case              1           1      1         0       1             1   \n",
       " Cecile            1           1      1         1       1             1   \n",
       " Charles          11          11     11         2      11            11   \n",
       " Chien             2           2      2         2       2             2   \n",
       "...              ...         ...    ...       ...     ...           ...   \n",
       " Roger             2           2      2         0       2             2   \n",
       " Ron               9           9      9         8       9             9   \n",
       " Ronald           27          27     27        20      27            27   \n",
       " Roy               5           5      5         1       5             5   \n",
       " Ruth             15          15     15         0      15            15   \n",
       " Ryan              4           4      4         4       4             4   \n",
       " S                14          14     14         2      14            14   \n",
       " Scott             2           2      2         2       2             2   \n",
       " Sean              1           1      1         0       1             1   \n",
       " Shawn             1           1      1         0       1             1   \n",
       " Stephen           2           2      2         1       2             2   \n",
       " Steve             3           3      3         3       3             3   \n",
       " Steven            2           2      2         1       2             2   \n",
       " Suong             1           1      1         0       1             1   \n",
       " Susan             1           1      1         0       1             1   \n",
       " Suzanne           3           3      3         3       3             3   \n",
       " T                 1           1      1         1       1             1   \n",
       " Thomas            5           5      5         4       5             5   \n",
       " Thuykien          4           4      4         4       4             4   \n",
       " Todd              1           1      1         1       1             1   \n",
       " Tom               1           1      1         0       1             1   \n",
       " Trong             4           4      4         4       4             4   \n",
       " Trudy             1           1      1         1       1             1   \n",
       " W                 3           3      3         1       3             3   \n",
       " Wil             149         149    149        34     149           149   \n",
       " William           4           4      4         3       4             4   \n",
       " Wilson           63          63     63        13      63            63   \n",
       " Yvonne            1           1      1         1       1             1   \n",
       " ave               1           1      1         1       1             1   \n",
       " lisa              1           1      1         1       1             1   \n",
       "\n",
       "            LessonDate  MissionDirectorate  SafetyIssue  Categories  DocNum  \\\n",
       "name_first                                                                    \n",
       " A                   5                   0            5           0       5   \n",
       " Al                  1                   1            1           0       1   \n",
       " Alan                1                   1            1           0       1   \n",
       " Albert              2                   2            2           0       2   \n",
       " Alicia              1                   1            1           0       1   \n",
       " Allan               1                   1            1           0       1   \n",
       " Amber               8                   1            8           8       8   \n",
       " Andre               2                   2            2           1       2   \n",
       " Angela              1                   0            1           1       1   \n",
       " Annette            93                  91           93          91      93   \n",
       " Anthony            12                  12           12           0      12   \n",
       " B                  10                   4           10           0      10   \n",
       " Barbara             3                   3            3           3       3   \n",
       " Barrie              1                   1            1           0       1   \n",
       " Bernard             7                   0            7           0       7   \n",
       " Bill                6                   3            6           0       6   \n",
       " Billy              17                  17           17           0      17   \n",
       " Bob                 1                   0            1           0       1   \n",
       " Bonita              8                   8            8           0       8   \n",
       " Brent               1                   0            1           1       1   \n",
       " Brian               1                   0            1           0       1   \n",
       " Bryant              1                   1            1           0       1   \n",
       " C                  16                   4           16           0      16   \n",
       " Calvert             1                   1            1           0       1   \n",
       " Carl                2                   1            2           1       2   \n",
       " Carol               3                   3            3           1       3   \n",
       " Case                1                   0            1           0       1   \n",
       " Cecile              1                   1            1           0       1   \n",
       " Charles            11                   5           11           0      11   \n",
       " Chien               2                   1            2           2       2   \n",
       "...                ...                 ...          ...         ...     ...   \n",
       " Roger               2                   1            2           0       2   \n",
       " Ron                 9                   4            9           6       9   \n",
       " Ronald             27                  22           27           1      27   \n",
       " Roy                 5                   5            5           0       5   \n",
       " Ruth               15                   0           15           0      15   \n",
       " Ryan                4                   4            4           3       4   \n",
       " S                  14                   0           14           0      14   \n",
       " Scott               2                   1            2           1       2   \n",
       " Sean                1                   0            1           0       1   \n",
       " Shawn               1                   0            1           0       1   \n",
       " Stephen             2                   1            2           0       2   \n",
       " Steve               3                   3            3           1       3   \n",
       " Steven              2                   2            2           0       2   \n",
       " Suong               1                   1            1           0       1   \n",
       " Susan               1                   0            1           0       1   \n",
       " Suzanne             3                   3            3           0       3   \n",
       " T                   1                   0            1           0       1   \n",
       " Thomas              5                   5            5           0       5   \n",
       " Thuykien            4                   4            4           4       4   \n",
       " Todd                1                   1            1           1       1   \n",
       " Tom                 1                   1            1           0       1   \n",
       " Trong               4                   4            4           0       4   \n",
       " Trudy               1                   1            1           1       1   \n",
       " W                   3                   1            3           0       3   \n",
       " Wil               149                 147          149           0     149   \n",
       " William             4                   4            4           1       4   \n",
       " Wilson             63                  51           63           0      63   \n",
       " Yvonne              1                   1            1           0       1   \n",
       " ave                 1                   1            1           0       1   \n",
       " lisa                1                   0            1           0       1   \n",
       "\n",
       "            Topic  Category  url  name_last  \n",
       "name_first                                   \n",
       " A              5         0    5          5  \n",
       " Al             1         0    1          1  \n",
       " Alan           1         0    1          1  \n",
       " Albert         2         0    2          2  \n",
       " Alicia         1         0    1          1  \n",
       " Allan          1         0    1          1  \n",
       " Amber          8         8    8          8  \n",
       " Andre          2         1    2          2  \n",
       " Angela         1         1    1          1  \n",
       " Annette       93        91   93         93  \n",
       " Anthony       12         0   12         12  \n",
       " B             10         0   10         10  \n",
       " Barbara        3         3    3          3  \n",
       " Barrie         1         0    1          1  \n",
       " Bernard        7         0    7          7  \n",
       " Bill           6         0    6          6  \n",
       " Billy         17         0   17         17  \n",
       " Bob            1         0    1          1  \n",
       " Bonita         8         0    8          8  \n",
       " Brent          1         1    1          1  \n",
       " Brian          1         0    1          1  \n",
       " Bryant         1         0    1          1  \n",
       " C             16         0   16         16  \n",
       " Calvert        1         0    1          1  \n",
       " Carl           2         1    2          2  \n",
       " Carol          3         1    3          3  \n",
       " Case           1         0    1          1  \n",
       " Cecile         1         0    1          1  \n",
       " Charles       11         0   11         11  \n",
       " Chien          2         2    2          2  \n",
       "...           ...       ...  ...        ...  \n",
       " Roger          2         0    2          2  \n",
       " Ron            9         6    9          9  \n",
       " Ronald        27         1   27         27  \n",
       " Roy            5         0    5          5  \n",
       " Ruth          15         0   15         15  \n",
       " Ryan           4         3    4          4  \n",
       " S             14         0   14         14  \n",
       " Scott          2         1    2          2  \n",
       " Sean           1         0    1          1  \n",
       " Shawn          1         0    1          1  \n",
       " Stephen        2         0    2          2  \n",
       " Steve          3         1    3          3  \n",
       " Steven         2         0    2          2  \n",
       " Suong          1         0    1          1  \n",
       " Susan          1         0    1          1  \n",
       " Suzanne        3         0    3          3  \n",
       " T              1         0    1          1  \n",
       " Thomas         5         0    5          5  \n",
       " Thuykien       4         4    4          4  \n",
       " Todd           1         1    1          1  \n",
       " Tom            1         0    1          1  \n",
       " Trong          4         0    4          4  \n",
       " Trudy          1         1    1          1  \n",
       " W              3         0    3          3  \n",
       " Wil          149         0  149        149  \n",
       " William        4         1    4          4  \n",
       " Wilson        63         0   63         63  \n",
       " Yvonne         1         0    1          1  \n",
       " ave            1         0    1          1  \n",
       " lisa           1         0    1          1  \n",
       "\n",
       "[181 rows x 15 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name_first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1637"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# confirm that LessonId is unique, it is\n",
    "lessonid = df.sort_values(by=['LessonId']).groupby(['LessonId']).count()\n",
    "len(lessonid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confirm that url is unique, it is\n",
    "url = df.sort_values(by=['url']).groupby(['url']).count()\n",
    "len(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submitter[:50]\n",
    "#submitter[50:100]\n",
    "#submitter[100:150]\n",
    "#submitter[150:200]\n",
    "#submitter[200:250]\n",
    "#submitter[250:300]\n",
    "submitter[300:350]\n",
    "submitter[350:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMDb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BOS = 'xbos'  # beginning-of-sentence tag\n",
    "FLD = 'xfld'  # data field tag\n",
    "\n",
    "#PATH=Path('data/aclImdb/')\n",
    "#PATH=Path(PATHproject+'/data/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardize format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CLAS_PATH=Path('data/imdb_clas/')\n",
    "CLAS_PATH=Path(PATHproject+'data/lessons_clas/')\n",
    "CLAS_PATH.mkdir(exist_ok=True)\n",
    "\n",
    "LM_PATH=Path(PATHproject+'data/lessons_lm/')\n",
    "LM_PATH.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The imdb dataset has 3 classes. positive, negative and unsupervised(sentiment is unknown). \n",
    "There are 75k training reviews(12.5k pos, 12.5k neg, 50k unsup)\n",
    "There are 25k validation reviews(12.5k pos, 12.5k neg & no unsup)\n",
    "\n",
    "Refer to the README file in the imdb corpus for further information about the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASSES = ['neg', 'pos', 'unsup']\n",
    "\n",
    "def get_texts(path):\n",
    "    texts,labels = [],[]\n",
    "    for idx,label in enumerate(CLASSES):\n",
    "        for fname in (path/label).glob('*.*'):\n",
    "            texts.append(fname.open('r', encoding='utf-8').read())\n",
    "            labels.append(idx)\n",
    "    return np.array(texts),np.array(labels)\n",
    "\n",
    "trn_texts,trn_labels = get_texts(PATH/'train')\n",
    "val_texts,val_labels = get_texts(PATH/'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(trn_texts),len(val_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names = ['labels','text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use a random permutation np array to shuffle the text reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "trn_idx = np.random.permutation(len(trn_texts))\n",
    "val_idx = np.random.permutation(len(val_texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_texts = trn_texts[trn_idx]\n",
    "val_texts = val_texts[val_idx]\n",
    "\n",
    "trn_labels = trn_labels[trn_idx]\n",
    "val_labels = val_labels[val_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trn = pd.DataFrame({'text':trn_texts, 'labels':trn_labels}, columns=col_names)\n",
    "df_val = pd.DataFrame({'text':val_texts, 'labels':val_labels}, columns=col_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pandas dataframe is used to store text data in a newly evolving standard format of label followed by text columns. This was influenced by a paper by Yann LeCun (LINK REQUIRED). Fastai adopts this new format for NLP datasets. In the case of IMDB, there is only one text column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trn[df_trn['labels']!=2].to_csv(CLAS_PATH/'train.csv', header=False, index=False)\n",
    "df_val.to_csv(CLAS_PATH/'test.csv', header=False, index=False)\n",
    "\n",
    "(CLAS_PATH/'classes.txt').open('w', encoding='utf-8').writelines(f'{o}\\n' for o in CLASSES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by creating the data for the Language Model(LM). The LM's goal is to learn the structure of the english language. It learns language by trying to predict the next word given a set of previous words(ngrams). Since the LM does not classify reviews, the labels can be ignored.\n",
    "\n",
    "The LM can benefit from all the textual data and there is no need to exclude the unsup/unclassified movie reviews.\n",
    "\n",
    "We first concat all the train(pos/neg/unsup = **75k**) and test(pos/neg=**25k**) reviews into a big chunk of **100k** reviews. And then we use sklearn splitter to divide up the 100k texts into 90% training and 10% validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_texts,val_texts = sklearn.model_selection.train_test_split(\n",
    "    np.concatenate([trn_texts,val_texts]), test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(trn_texts), len(val_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trn = pd.DataFrame({'text':trn_texts, 'labels':[0]*len(trn_texts)}, columns=col_names)\n",
    "df_val = pd.DataFrame({'text':val_texts, 'labels':[0]*len(val_texts)}, columns=col_names)\n",
    "\n",
    "df_trn.to_csv(LM_PATH/'train.csv', header=False, index=False)\n",
    "df_val.to_csv(LM_PATH/'test.csv', header=False, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Language model tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we start cleaning up the messy text. There are 2 main activities we need to perform:\n",
    "\n",
    "1. Clean up extra spaces, tab chars, new ln chars and other characters and replace them with standard ones\n",
    "2. Use the awesome [spacy](http://spacy.io) library to tokenize the data. Since spacy does not provide a parallel/multicore version of the tokenizer, the fastai library adds this functionality. This parallel version uses all the cores of your CPUs and runs much faster than the serial version of the spacy tokenizer.\n",
    "\n",
    "Tokenization is the process of splitting the text into separate tokens so that each token can be assigned a unique index. This means we can convert the text into integer indexes our models can use.\n",
    "\n",
    "We use an appropriate chunksize as the tokenization process is memory intensive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunksize=24000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "re1 = re.compile(r'  +')\n",
    "\n",
    "def fixup(x):\n",
    "    x = x.replace('#39;', \"'\").replace('amp;', '&').replace('#146;', \"'\").replace(\n",
    "        'nbsp;', ' ').replace('#36;', '$').replace('\\\\n', \"\\n\").replace('quot;', \"'\").replace(\n",
    "        '<br />', \"\\n\").replace('\\\\\"', '\"').replace('<unk>','u_n').replace(' @.@ ','.').replace(\n",
    "        ' @-@ ','-').replace('\\\\', ' \\\\ ')\n",
    "    return re1.sub(' ', html.unescape(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_texts(df, n_lbls=1):\n",
    "    labels = df.iloc[:,range(n_lbls)].values.astype(np.int64)\n",
    "    texts = f'\\n{BOS} {FLD} 1 ' + df[n_lbls].astype(str)\n",
    "    for i in range(n_lbls+1, len(df.columns)): texts += f' {FLD} {i-n_lbls} ' + df[i].astype(str)\n",
    "    texts = list(texts.apply(fixup).values)\n",
    "\n",
    "    tok = Tokenizer().proc_all_mp(partition_by_cores(texts))\n",
    "    return tok, list(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all(df, n_lbls):\n",
    "    tok, labels = [], []\n",
    "    for i, r in enumerate(df):\n",
    "        print(i)\n",
    "        tok_, labels_ = get_texts(r, n_lbls)\n",
    "        tok += tok_;\n",
    "        labels += labels_\n",
    "    return tok, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trn = pd.read_csv(LM_PATH/'train.csv', header=None, chunksize=chunksize)\n",
    "df_val = pd.read_csv(LM_PATH/'test.csv', header=None, chunksize=chunksize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tok_trn, trn_labels = get_all(df_trn, 1)\n",
    "tok_val, val_labels = get_all(df_val, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(LM_PATH/'tmp').mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(LM_PATH/'tmp'/'tok_trn.npy', tok_trn)\n",
    "np.save(LM_PATH/'tmp'/'tok_val.npy', tok_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tok_trn = np.load(LM_PATH/'tmp'/'tok_trn.npy')\n",
    "tok_val = np.load(LM_PATH/'tmp'/'tok_val.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "freq = Counter(p for o in tok_trn for p in o)\n",
    "freq.most_common(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The *vocab* is the **unique set of all tokens** in our dataset. The vocab provides us a way for us to simply replace each word in our datasets with a unique integer called an index.\n",
    "\n",
    "In a large corpus of data one might find some rare words which are only used a few times in the whole dataset. We discard such rare words and avoid trying to learn meaningful patterns out of them.\n",
    "\n",
    "Here we have set a minimum frequency of occurence to 2 times. It has been observed by NLP practicioners that a maximum vocab of 60k usually yields good results for classification tasks. So we set maz_vocab to 60000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_vocab = 60000\n",
    "min_freq = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "itos = [o for o,c in freq.most_common(max_vocab) if c>min_freq]\n",
    "itos.insert(0, '_pad_')\n",
    "itos.insert(0, '_unk_')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a reverse mapping called stoi which is useful to lookup the index of a given token. stoi also has the same number of elements as itos. We use a high performance container called [collections.defaultdict](https://docs.python.org/2/library/collections.html#collections.defaultdict) to store our stoi mapping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stoi = collections.defaultdict(lambda:0, {v:k for k,v in enumerate(itos)})\n",
    "len(itos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_lm = np.array([[stoi[o] for o in p] for p in tok_trn])\n",
    "val_lm = np.array([[stoi[o] for o in p] for p in tok_val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(LM_PATH/'tmp'/'trn_ids.npy', trn_lm)\n",
    "np.save(LM_PATH/'tmp'/'val_ids.npy', val_lm)\n",
    "pickle.dump(itos, open(LM_PATH/'tmp'/'itos.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_lm = np.load(LM_PATH/'tmp'/'trn_ids.npy')\n",
    "val_lm = np.load(LM_PATH/'tmp'/'val_ids.npy')\n",
    "itos = pickle.load(open(LM_PATH/'tmp'/'itos.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vs=len(itos)\n",
    "vs,len(trn_lm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## wikitext103 conversion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now going to build an english language model for the IMDB corpus. We could start from scratch and try to learn the structure of the english language. But we use a technique called transfer learning to make this process easier. In transfer learning (a fairly recent idea for NLP) a pre-trained LM that has been trained on a large generic corpus(_like wikipedia articles_) can be used to transfer it's knowledge to a target LM and the weights can be fine-tuned.\n",
    "\n",
    "Our source LM is the wikitext103 LM created by Stephen Merity @ Salesforce research. [Link to dataset](https://www.salesforce.com/products/einstein/ai-research/the-wikitext-dependency-language-modeling-dataset/)\n",
    "The language model for wikitext103 (AWD LSTM) has been pre-trained and the weights can be downloaded here: [Link](http://files.fast.ai/models/wt103/). Our target LM is the IMDB LM. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! wget -nH -r -np -P {PATH} http://files.fast.ai/models/wt103/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pre-trained LM weights have an embedding size of 400, 1150 hidden units and just 3 layers. We need to match these values  with the target IMDB LM so that the weights can be loaded up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "em_sz,nh,nl = 400,1150,3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRE_PATH = PATH/'models'/'wt103'\n",
    "PRE_LM_PATH = PRE_PATH/'fwd_wt103.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wgts = torch.load(PRE_LM_PATH, map_location=lambda storage, loc: storage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We calculate the mean of the layer0 encoder weights. This can be used to assign weights to unknown tokens when we transfer to target IMDB LM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_wgts = to_np(wgts['0.encoder.weight'])\n",
    "row_m = enc_wgts.mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "itos2 = pickle.load((PRE_PATH/'itos_wt103.pkl').open('rb'))\n",
    "stoi2 = collections.defaultdict(lambda:-1, {v:k for k,v in enumerate(itos2)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we try to transfer the knowledge from wikitext to the IMDB LM, we match up the vocab words and their indexes. \n",
    "We use the defaultdict container once again, to assign mean weights to unknown IMDB tokens that do not exist in wikitext103."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_w = np.zeros((vs, em_sz), dtype=np.float32)\n",
    "for i,w in enumerate(itos):\n",
    "    r = stoi2[w]\n",
    "    new_w[i] = enc_wgts[r] if r>=0 else row_m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now overwrite the weights into the wgts odict.\n",
    "The decoder module, which we will explore in detail is also loaded with the same weights due to an idea called weight tying."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wgts['0.encoder.weight'] = T(new_w)\n",
    "wgts['0.encoder_with_dropout.embed.weight'] = T(np.copy(new_w))\n",
    "wgts['1.decoder.weight'] = T(np.copy(new_w))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the weights prepared, we are ready to create and start training our new IMDB language pytorch model!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Language model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is fairly straightforward to create a new language model using the fastai library. Like every other lesson, our model will have a backbone and a custom head. The backbone in our case is the IMDB LM pre-trained with wikitext and the custom head is a linear classifier. In this section we will focus on the backbone LM and the next section will talk about the classifier custom head.\n",
    "\n",
    "bptt (*also known traditionally in NLP LM as ngrams*) in fastai LMs is approximated to a std. deviation around 70, by perturbing the sequence length on a per-batch basis. This is akin to shuffling our data in computer vision, only that in NLP we cannot shuffle inputs and we have to maintain statefulness. \n",
    "\n",
    "Since we are predicting words using ngrams, we want our next batch to line up with the end-points of the previous mini-batch's items. batch-size is constant and but the fastai library expands and contracts bptt each mini-batch using a clever stochastic implementation of a batch. (original credits attributed to [Smerity](https://twitter.com/jeremyphoward/status/980227258395770882))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wd=1e-7\n",
    "bptt=70\n",
    "bs=52\n",
    "opt_fn = partial(optim.Adam, betas=(0.8, 0.99))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of the LM is to learn to predict a word/token given a preceeding set of words(tokens). We take all the movie reviews in both the 90k training set and 10k validation set and concatenate them to form long strings of tokens. In fastai, we use the `LanguageModelLoader` to create a data loader which makes it easy to create and use bptt sized mini batches. The  `LanguageModelLoader` takes a concatenated string of tokens and returns a loader.\n",
    "\n",
    "We have a special modeldata object class for LMs called `LanguageModelData` to which we can pass the training and validation loaders and get in return the model itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_dl = LanguageModelLoader(np.concatenate(trn_lm), bs, bptt)\n",
    "val_dl = LanguageModelLoader(np.concatenate(val_lm), bs, bptt)\n",
    "md = LanguageModelData(PATH, 1, vs, trn_dl, val_dl, bs=bs, bptt=bptt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We setup the dropouts for the model - these values have been chosen after experimentation. If you need to update them for custom LMs, you can change the weighting factor (0.7 here) based on the amount of data you have. For more data, you can reduce dropout factor and for small datasets, you can reduce overfitting by choosing a higher dropout factor. *No other dropout value requires tuning*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drops = np.array([0.25, 0.1, 0.2, 0.02, 0.15])*0.7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first tune the last embedding layer so that the missing tokens initialized with mean weights get tuned properly. So we freeze everything except the last layer.\n",
    "\n",
    "We also keep track of the *accuracy* metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner= md.get_model(opt_fn, em_sz, nh, nl, \n",
    "    dropouti=drops[0], dropout=drops[1], wdrop=drops[2], dropoute=drops[3], dropouth=drops[4])\n",
    "\n",
    "learner.metrics = [accuracy]\n",
    "learner.freeze_to(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.model.load_state_dict(wgts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We set learning rates and fit our IMDB LM. We first run one epoch to tune the last layer which contains the embedding weights. This should help the missing tokens in the wikitext103 learn better weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=1e-3\n",
    "lrs = lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.fit(lrs/2, 1, wds=wd, use_clr=(32,2), cycle_len=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we print out accuracy and keep track of how often we end up predicting the target word correctly. While this is a good metric to check, it is not part of our loss function as it can get quite bumpy. We only minimize cross-entropy loss in the LM.\n",
    "\n",
    "The exponent of the cross-entropy loss is called the perplexity of the LM. (low perplexity is better)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.save('lm_last_ft')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.load('lm_last_ft')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.unfreeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.lr_find(start_lr=lrs/10, end_lr=lrs*10, linear=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.sched.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "learner.fit(lrs, 1, wds=wd, use_clr=(20,10), cycle_len=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We save the trained model weights and separately save the encoder part of the LM model as well. This will serve as our backbone in the classification task model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.save('lm1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.save_encoder('lm1_enc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.sched.plot_loss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifier tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The classifier model is basically a linear layer custom head on top of the LM backbone. Setting up the classifier data is similar to the LM data setup except that we cannot use the unsup movie reviews this time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trn = pd.read_csv(CLAS_PATH/'train.csv', header=None, chunksize=chunksize)\n",
    "df_val = pd.read_csv(CLAS_PATH/'test.csv', header=None, chunksize=chunksize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tok_trn, trn_labels = get_all(df_trn, 1)\n",
    "tok_val, val_labels = get_all(df_val, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(CLAS_PATH/'tmp').mkdir(exist_ok=True)\n",
    "\n",
    "np.save(CLAS_PATH/'tmp'/'tok_trn.npy', tok_trn)\n",
    "np.save(CLAS_PATH/'tmp'/'tok_val.npy', tok_val)\n",
    "\n",
    "np.save(CLAS_PATH/'tmp'/'trn_labels.npy', trn_labels)\n",
    "np.save(CLAS_PATH/'tmp'/'val_labels.npy', val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tok_trn = np.load(CLAS_PATH/'tmp'/'tok_trn.npy')\n",
    "tok_val = np.load(CLAS_PATH/'tmp'/'tok_val.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "itos = pickle.load((LM_PATH/'tmp'/'itos.pkl').open('rb'))\n",
    "stoi = collections.defaultdict(lambda:0, {v:k for k,v in enumerate(itos)})\n",
    "len(itos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_clas = np.array([[stoi[o] for o in p] for p in tok_trn])\n",
    "val_clas = np.array([[stoi[o] for o in p] for p in tok_val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(CLAS_PATH/'tmp'/'trn_ids.npy', trn_clas)\n",
    "np.save(CLAS_PATH/'tmp'/'val_ids.npy', val_clas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can create our final model, a classifier which is really a custom linear head over our trained IMDB backbone. The steps to create the classifier model are similar to the ones for the LM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_clas = np.load(CLAS_PATH/'tmp'/'trn_ids.npy')\n",
    "val_clas = np.load(CLAS_PATH/'tmp'/'val_ids.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_labels = np.squeeze(np.load(CLAS_PATH/'tmp'/'trn_labels.npy'))\n",
    "val_labels = np.squeeze(np.load(CLAS_PATH/'tmp'/'val_labels.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bptt,em_sz,nh,nl = 70,400,1150,3\n",
    "vs = len(itos)\n",
    "opt_fn = partial(optim.Adam, betas=(0.8, 0.99))\n",
    "bs = 48"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_lbl = trn_labels.min()\n",
    "trn_labels -= min_lbl\n",
    "val_labels -= min_lbl\n",
    "c=int(trn_labels.max())+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the classifier, unlike LM, we need to read a movie review at a time and learn to predict the it's sentiment as pos/neg. We do not deal with equal bptt size batches, so we have to pad the sequences to the same length in each batch. To create batches of similar sized movie reviews, we use a sortish sampler method invented by [@Smerity](https://twitter.com/Smerity) and [@jekbradbury](https://twitter.com/jekbradbury)\n",
    "\n",
    "The sortishSampler cuts down the overall number of padding tokens the classifier ends up seeing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_ds = TextDataset(trn_clas, trn_labels)\n",
    "val_ds = TextDataset(val_clas, val_labels)\n",
    "trn_samp = SortishSampler(trn_clas, key=lambda x: len(trn_clas[x]), bs=bs//2)\n",
    "val_samp = SortSampler(val_clas, key=lambda x: len(val_clas[x]))\n",
    "trn_dl = DataLoader(trn_ds, bs//2, transpose=True, num_workers=1, pad_idx=1, sampler=trn_samp)\n",
    "val_dl = DataLoader(val_ds, bs, transpose=True, num_workers=1, pad_idx=1, sampler=val_samp)\n",
    "md = ModelData(PATH, trn_dl, val_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# part 1\n",
    "dps = np.array([0.4, 0.5, 0.05, 0.3, 0.1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dps = np.array([0.4,0.5,0.05,0.3,0.4])*0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = get_rnn_classifier(bptt, 20*70, c, vs, emb_sz=em_sz, n_hid=nh, n_layers=nl, pad_token=1,\n",
    "          layers=[em_sz*3, 50, c], drops=[dps[4], 0.1],\n",
    "          dropouti=dps[0], wdrop=dps[1], dropoute=dps[2], dropouth=dps[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_fn = partial(optim.Adam, betas=(0.7, 0.99))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = RNN_Learner(md, TextModel(to_gpu(m)), opt_fn=opt_fn)\n",
    "learn.reg_fn = partial(seq2seq_reg, alpha=2, beta=1)\n",
    "learn.clip=.25\n",
    "learn.metrics = [accuracy]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=3e-3\n",
    "lrm = 2.6\n",
    "lrs = np.array([lr/(lrm**4), lr/(lrm**3), lr/(lrm**2), lr/lrm, lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrs=np.array([1e-4,1e-4,1e-4,1e-3,1e-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wd = 1e-7\n",
    "wd = 0\n",
    "learn.load_encoder('lm1_enc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.freeze_to(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.lr_find(lrs/1000)\n",
    "learn.sched.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(lrs, 1, wds=wd, cycle_len=1, use_clr=(8,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('clas_0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load('clas_0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.freeze_to(-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(lrs, 1, wds=wd, cycle_len=1, use_clr=(8,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('clas_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load('clas_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.unfreeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(lrs, 1, wds=wd, cycle_len=14, use_clr=(32,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.sched.plot_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('clas_2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The previous state of the art result was 94.1% accuracy (5.9% error). With bidir we get 95.4% accuracy (4.6% error)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.sched.plot_loss()"
   ]
  }
 ],
 "metadata": {
  "_draft": {
   "nbviewer_url": "https://gist.github.com/0dd0df21cf404cf2bb51d0148c8b7d8b"
  },
  "gist": {
   "data": {
    "description": "fastai.text imdb example",
    "public": true
   },
   "id": "0dd0df21cf404cf2bb51d0148c8b7d8b"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "86px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
